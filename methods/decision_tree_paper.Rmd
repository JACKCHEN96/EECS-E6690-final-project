---
title: "decision_tree_paper"
author: "Wenjie Chen"
date: "12/4/2019"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. 

```{r}
library("readxl")
data1 = read_excel("../data/1415CSM_dataset.xlsx")
i=1
data1=na.omit(data1)
asLabel=""
for (val in data1$Ratings) {
  if(val<=4.9){
    asLabel[i]="Poor"
  }else if(val<=6.4){
    asLabel[i]="Average"
  }else if(val<=8.9){
    asLabel[i]="Good"
  }else if(val<=10){
    asLabel[i]="Excellent"
  }
  i=i+1
}
# print(asLabel)
data1 = data.frame(data1,asLabel)
# print(data1)
set.seed(10)
datasize = dim(data1)[1]
train_idx = sample(datasize, datasize*0.9)

indicator1 = rep(0,datasize)
indicator1[train_idx] = 1 # 1:train 0:valid
data1 = data.frame(data1,indicator1)
# print(data1)
```

## Decision Tree
```{r}
# library(RWeka)
# library(party)

library(tree)
train = subset(data1,data1$indicator1==1)
valid = subset(data1,data1$indicator1==0)

ctt1 = tree(asLabel~.-Year-Movie-Ratings,train)
# ctt1 = J48(asLabel~.-Year-Movie-Ratings,train)
# if(require("party", quietly = TRUE)) plot(m1)
```

## Prune Tree
```{r}
ctt1 = tree(asLabel~.-Year-Movie-Ratings,train,mindev=0.02)
# I change mindev from 0.01 to 0.9 to see the best performance. choose 0.03
```

## Plot tree
```{r}
plot(ctt1)
text(ctt1)
summary(ctt1)
ctt1
```
```{r}
library(rpart)
library(rpart.plot)
pretty_tree=rpart(asLabel~.-Year-Movie-Ratings,data=train,cp=0.001)
rpart.plot(pretty_tree,box.palette = "RdBu",shadow.col = "gray",nn=TRUE)
```
## Predict (below with the train and validation set)
```{r}
PredLabel1 = predict(ctt1,train,type="class")
PredTreeScore1 = data.frame(predict(ctt1,train,type="vector"))
train = data.frame(train,PredLabel1,PredTreeScore1)

## valid
PredLabelValid1 = predict(ctt1,valid,type="class")
PredTreeScoreValid1 = data.frame(predict(ctt1,valid,type="vector"))
valid = data.frame(valid,PredLabelValid1,PredTreeScoreValid1)
```

```{r}
# print(valid$PredLabelValid1)
# print(valid$asLabel)
```
## Give out the validation error rate
```{r}
tablev1 = table(valid$PredLabelValid1,valid$asLabel)
error_valid1 = 1 - sum(diag(tablev1)) / sum(tablev1)
error_valid1
print(tablev1)
```

## The following code block is lable_tran_num function. We may use it.
```{r}
# # train
# print(train$asLabel)
# print(train$Ratings)
# print(PredTreeScore1)
# print(train$asLabel_d)
# label2point=0;

# n=1
# for (m in train$asLabel) {
#   if(identical(m,"Poor")){
#     label2point[n]=1
#   }else if(identical(m,"Average")){
#     label2point[n]=2
#   }else if(identical(m,"Good")){
#     label2point[n]=3
#   }else if(identical(m,"Excellent")){
#     label2point[n]=4
#   }
#   n=n+1
# }
# print(label2point)
# 
# label2point_valid=0;
# q=1
# for (p in valid$asLabel) {
#   if(identical(p,"Poor")){
#     label2point_valid[q]=1
#   }else if(identical(p,"Average")){
#     label2point_valid[q]=2
#   }else if(identical(p,"Good")){
#     label2point_valid[q]=3
#   }else if(identical(p,"Excellent")){
#     label2point_valid[q]=4
#   }
#   q=q+1
# }
# print(label2point_valid)
# # train_res=(PredTreeScore1$Poor)*4.9+(PredTreeScore1$Average)*6.4+(PredTreeScore1$Good)*8.9
# # print(train_res)
# 
# train_res_label=1:184
# n=1
# for (m in 1:184) {
#   if((PredTreeScore1[m,]$Poor)>0.5){
#     train_res_label[n]=1
#   }else if((PredTreeScore1[m,]$Average)>0.5){
#     train_res_label[n]=2
#   }else if((PredTreeScore1[m,]$Good)>0.5){
#     train_res_label[n]=3
#   }
#   n=n+1
# }
# print(train_res_label)
# 
# val_res_label=1:47
# n=1
# for (m in 1:47) {
#   if((PredTreeScoreValid1[m,]$Poor)>0.5){
#     val_res_label[n]=1
#   }else if((PredTreeScoreValid1[m,]$Average)>0.5){
#     val_res_label[n]=2
#   }else if((PredTreeScoreValid1[m,]$Good)>0.5){
#     val_res_label[n]=3
#   }
#   n=n+1
# }
# # print(train_res_label)
# print(val_res_label)
```


```{r}
# # gtt = gains(actual=train$asLabel,predicted=PredTreeScore1,optimal=TRUE)
# library("gains")
# gtt = gains(actual=label2point,
#             predicted=train_res_label,
#             optimal=TRUE)
# cpt_y = gtt$cume.pct.of.total
# cpt_x = gtt$depth
# # 
# # # validation
# 
# # print((PredTreeScoreValid1$Poor)*4.9+(PredTreeScoreValid1$Average)*6.4+(PredTreeScoreValid1$Good)*8.9)
# # 
# gtv = gains(actual=label2point_valid,
#             predicted=val_res_label,
#             optimal=TRUE)
# cpv_y = gtv$cume.pct.of.total
# cpv_x = gtv$depth
```






