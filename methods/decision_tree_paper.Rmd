---
title: "decision_tree_paper"
author: "Wenjie Chen"
date: "12/4/2019"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. 

```{r}
library("readxl")
data1 = read_excel("../data/1415CSM_dataset.xlsx")
i=1
asLabel=""
for (val in data1$Ratings) {
  if(val<=4.9){
    asLabel[i]="Poor"
  }else if(val<=6.4){
    asLabel[i]="Average"
  }else if(val<=8.9){
    asLabel[i]="Good"
  }else if(val<=10){
    asLabel[i]="Excellent"
  }
  i=i+1
}
# print(asLabel)
data1 = data.frame(data1,asLabel)
# print(data1)
set.seed(10)
datasize = dim(data1)[1]
train_idx = sample(datasize, datasize*0.8)

indicator1 = rep(0,datasize)
indicator1[train_idx] = 1 # 1:train 0:valid
data1 = data.frame(data1,indicator1)
```

## Decision Tree
```{r}
library(tree)
train = subset(data1,data1$indicator1==1)
valid = subset(data1,data1$indicator1==0)

ctt1 = tree(asLabel~.-Year-Movie-Ratings,train)
#ctv = tree(High~.-X.U.FEFF.ID-indicator-default.payment.next.month,valid)

```

## Prune Tree
```{r}
ctt1 = tree(asLabel~.-Year-Movie-Ratings,train,mindev=0.03)
# I change mindev from 0.01 to 0.9 to see the best performance. choose 0.03
```

## Plot tree
```{r}
plot(ctt1)
text(ctt1)
summary(ctt1)
ctt1
```
## Predict (below with the train and validation set)
```{r}
PredLabel1 = predict(ctt1,train,type="class")
PredTreeScore1 = data.frame(predict(ctt1,train,type="vector"))
train = data.frame(train,PredLabel1,PredTreeScore1)

## valid
PredLabelValid1 = predict(ctt1,valid,type="class")
PredTreeScoreValid1 = data.frame(predict(ctt1,valid,type="vector"))
valid = data.frame(valid,PredLabelValid1,PredTreeScoreValid1)
```

## Give out the validation error rate, which is 0.426, not bad.
```{r}
tablev1 = table(valid$PredLabelValid1,valid$asLabel)
error_valid1 = 1 - sum(diag(tablev1)) / sum(tablev1)
error_valid1
```
## Gains
```{r}
# # train
print(asLabel)
# print(train$Ratings)
print(PredTreeScore1)
# print(PredTreeScore1$Poor)
# print(PredTreeScore1$Average)
# print(PredTreeScore1$Good)

# label2point=0;
# n=1
# for (m in train$asLabel) {
#   if(identical(m,"Poor")){
#     label2point[n]=4.9
#   }else if(identical(m,"Average")){
#     label2point[n]=6.4
#   }else if(identical(m,"Good")){
#     label2point[n]=8.9
#   }else if(identical(m,"Excellent")){
#     label2point[n]=10
#   }
#   n=n+1
# }
# print(label2point)

# train_res=(PredTreeScore1$Poor)*4.9+(PredTreeScore1$Average)*6.4+(PredTreeScore1$Good)*8.9
# print(train_res)
train_res_label=""
n=1
for (m in train_res) {
  if((PredTreeScore1$Poor)>0.5){
    train_res_label[n]="Poor"
  }else if((PredTreeScore1$Average)>0.5){
    train_res_label[n]="Average"
  }else if((PredTreeScore1$Good)>0.5){
    train_res_label[n]="Good"
  }
  n=n+1
}
print(train_res_label)
```


```{r}
# gtt = gains(actual=train$asLabel,predicted=PredTreeScore1,optimal=TRUE)
gtt = gains(actual=label2point,
            predicted=(PredTreeScore1$Poor)*4.9+(PredTreeScore1$Average)*6.4+(PredTreeScore1$Good)*8.9,
            optimal=TRUE)
cpt_y = gtt$cume.pct.of.total
cpt_x = gtt$depth

# # validation
label2point_valid=0;
q=1
for (p in valid$asLabel) {
  if(identical(p,"Poor")){
    label2point_valid[q]=4.9
  }else if(identical(p,"Average")){
    label2point_valid[q]=6.4
  }else if(identical(p,"Good")){
    label2point_valid[q]=8.9
  }else if(identical(p,"Excellent")){
    label2point_valid[q]=10
  }
  q=q+1
}
print(label2point_valid)
print((PredTreeScoreValid1$Poor)*4.9+(PredTreeScoreValid1$Average)*6.4+(PredTreeScoreValid1$Good)*8.9)

# gtv = gains(actual=valid$asLabel,predicted=valid$PredTreeScoreValid,optimal=TRUE)
gtv = gains(actual=label2point_valid,
            predicted=(PredTreeScoreValid1$Poor)*4.9+(PredTreeScoreValid1$Average)*6.4+(PredTreeScoreValid1$Good)*8.9,
            optimal=TRUE)
cpv_y = gtv$cume.pct.of.total
cpv_x = gtv$depth
```






